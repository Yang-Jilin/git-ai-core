from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import time
from app.core.ai_manager import AIManager
from app.core.advanced_smart_conversation_manager import advanced_smart_conversation_manager

router = APIRouter()

class ChatRequest(BaseModel):
    provider: str = Field(..., description="AI provider name")
    model: str = Field(..., description="Model name")
    messages: List[Dict[str, str]] = Field(..., description="Chat messages")
    api_key: str = Field(..., description="API key")
    base_url: Optional[str] = Field(None, description="Custom base URL")
    temperature: Optional[float] = Field(0.7, description="Temperature for generation")
    max_tokens: Optional[int] = Field(2000, description="Maximum tokens to generate")

class TestConnectionRequest(BaseModel):
    provider: str = Field(..., description="AI provider name")
    api_key: str = Field(..., description="API key")
    base_url: Optional[str] = Field(None, description="Custom base URL")

class GenerateCommentsRequest(BaseModel):
    file_path: str = Field(..., description="File path to generate comments for")
    file_content: str = Field(..., description="File content")
    language: str = Field(..., description="Programming language")
    comment_style: str = Field("detailed", description="Comment style: detailed, brief, documentation")
    provider: str = Field(..., description="AI provider")
    model: str = Field(..., description="AI model")
    api_key: str = Field(..., description="API key")

class AnalyzeArchitectureRequest(BaseModel):
    project_path: str = Field(..., description="Project path")
    file_tree: Dict[str, Any] = Field(..., description="Project file tree")
    project_info: Dict[str, Any] = Field(..., description="Project information")
    provider: str = Field(..., description="AI provider")
    model: str = Field(..., description="AI model")
    api_key: str = Field(..., description="API key")

class SmartConversationRequest(BaseModel):
    project_path: str = Field(..., description="Project path")
    conversation_id: Optional[str] = Field(None, description="Conversation ID")
    message: Optional[str] = Field(None, description="User message")

class ProviderConfig(BaseModel):
    name: str
    icon: str
    description: str
    models: List[str]
    default_base_url: str
    requires_api_key: bool

ai_manager = AIManager()

@router.get("/providers")
async def get_providers() -> Dict[str, ProviderConfig]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„AIä¾›åº”å•†é…ç½®"""
    return ai_manager.get_available_providers()

@router.post("/chat")
async def chat(request: ChatRequest) -> Dict[str, Any]:
    """å‘é€èŠå¤©æ¶ˆæ¯åˆ°AI"""
    try:
        response = await ai_manager.chat(
            provider=request.provider,
            model=request.model,
            messages=request.messages,
            api_key=request.api_key,
            base_url=request.base_url,
            temperature=request.temperature,
            max_tokens=request.max_tokens
        )
        return response
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI service error: {str(e)}")

@router.post("/test-connection")
async def test_connection(request: TestConnectionRequest) -> Dict[str, bool]:
    """æµ‹è¯•AIä¾›åº”å•†è¿æ¥"""
    try:
        success = await ai_manager.test_connection(
            provider=request.provider,
            api_key=request.api_key,
            base_url=request.base_url
        )
        return {"success": success}
    except Exception as e:
        return {"success": False, "error": str(e)}

@router.get("/models/{provider}")
async def get_models(provider: str) -> List[str]:
    """è·å–æŒ‡å®šä¾›åº”å•†çš„å¯ç”¨æ¨¡å‹"""
    config = ai_manager.get_provider_config(provider)
    if not config:
        raise HTTPException(status_code=404, detail="Provider not found")
    return config.get("models", [])

@router.post("/generate-comments")
async def generate_comments(request: GenerateCommentsRequest) -> Dict[str, Any]:
    """ä¸ºä»£ç æ–‡ä»¶ç”Ÿæˆæ³¨é‡Š"""
    try:
        # æ„å»ºAIæç¤ºè¯
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç æ–‡æ¡£ç”Ÿæˆå™¨ã€‚è¯·ä¸ºä»¥ä¸‹{request.language}ä»£ç ç”Ÿæˆé«˜è´¨é‡çš„æ³¨é‡Šã€‚

è¦æ±‚ï¼š
1. åªè¿”å›æ³¨é‡Šå†…å®¹ï¼Œä¸è¦ä¿®æ”¹åŸä»£ç 
2. ä½¿ç”¨{request.language}çš„é€‚å½“æ³¨é‡Šé£æ ¼
3. ä¸ºå‡½æ•°ã€ç±»ã€å¤æ‚é€»è¾‘æ·»åŠ è¯¦ç»†æ³¨é‡Š
4. ä¿æŒæ³¨é‡Šç®€æ´æ˜äº†
5. æ³¨é‡Šé£æ ¼ï¼š{request.comment_style}

ä»£ç ï¼š
{request.file_content}
        """.strip()

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç æ–‡æ¡£ç”ŸæˆåŠ©æ‰‹ï¼Œä¸“æ³¨äºç”Ÿæˆé«˜è´¨é‡çš„ä»£ç æ³¨é‡Šã€‚"},
            {"role": "user", "content": prompt}
        ]

        response = await ai_manager.chat(
            provider=request.provider,
            model=request.model,
            messages=messages,
            api_key=request.api_key,
            temperature=0.3,  # ä½æ¸©åº¦ç¡®ä¿æ³¨é‡Šå‡†ç¡®æ€§
            max_tokens=2000
        )
        
        return {
            "comments": response["content"],
            "file_path": request.file_path,
            "language": request.language,
            "usage": response.get("usage", {})
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Comment generation failed: {str(e)}")

@router.post("/analyze-architecture")
async def analyze_architecture(request: AnalyzeArchitectureRequest) -> Dict[str, Any]:
    """åˆ†æé¡¹ç›®æ¶æ„å¹¶ç”Ÿæˆå¯è§†åŒ–æ–‡æ¡£"""
    try:
        # æ„å»ºAIæç¤ºè¯
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶æ¶æ„å¸ˆã€‚è¯·åˆ†æä»¥ä¸‹é¡¹ç›®çš„æ¶æ„å¹¶ç”Ÿæˆè¯¦ç»†çš„æ¶æ„æ–‡æ¡£ã€‚

é¡¹ç›®ä¿¡æ¯ï¼š
- è·¯å¾„: {request.project_path}
- åç§°: {request.project_info.get('name', 'Unknown')}
- åˆ†æ”¯: {request.project_info.get('current_branch', 'Unknown')}
- æäº¤æ•°: {request.project_info.get('commits_count', 0)}

æ–‡ä»¶ç»“æ„ï¼š
{format_file_tree_for_ai(request.file_tree)}

è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„æ¶æ„æ–‡æ¡£ï¼š
1. é¡¹ç›®æ¦‚è¿°å’ŒæŠ€æœ¯æ ˆåˆ†æ
2. ä¸»è¦æ¨¡å—å’Œç»„ä»¶è¯´æ˜
3. ä¾èµ–å…³ç³»åˆ†æ
4. æ¶æ„å›¾ï¼ˆä½¿ç”¨Mermaidè¯­æ³•ï¼‰
5. æ”¹è¿›å»ºè®®

è¯·ä½¿ç”¨Markdownæ ¼å¼è¿”å›ï¼ŒåŒ…å«æ¸…æ™°çš„æ ‡é¢˜å’Œç»“æ„ã€‚
        """.strip()

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è½¯ä»¶æ¶æ„åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æä»£ç æ¶æ„å¹¶ç”Ÿæˆè¯¦ç»†çš„æ–‡æ¡£ã€‚"},
            {"role": "user", "content": prompt}
        ]

        response = await ai_manager.chat(
            provider=request.provider,
            model=request.model,
            messages=messages,
            api_key=request.api_key,
            temperature=0.7,
            max_tokens=3000
        )
        
        return {
            "architecture_doc": response["content"],
            "project_path": request.project_path,
            "usage": response.get("usage", {})
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Architecture analysis failed: {str(e)}")

# è¾…åŠ©å‡½æ•°
def format_file_tree_for_ai(tree: Dict[str, Any], indent: int = 0) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶æ ‘ä¸ºAIå¯è¯»çš„å­—ç¬¦ä¸²"""
    if tree.get("type") == "file":
        return "  " * indent + f"ğŸ“„ {tree['name']}\n"
    
    result = "  " * indent + f"ğŸ“ {tree['name']}/\n"
    for child in tree.get("children", []):
        result += format_file_tree_for_ai(child, indent + 1)
    return result

# æ™ºèƒ½å¯¹è¯ç«¯ç‚¹
@router.post("/smart-conversation/start")
async def start_smart_conversation(request: SmartConversationRequest) -> Dict[str, Any]:
    """å¼€å§‹æ™ºèƒ½å¯¹è¯ä¼šè¯"""
    try:
        # ç”Ÿæˆä¼šè¯ID
        conversation_id = f"conv_{int(time.time() * 1000)}"
        
        # è·å–é¡¹ç›®æ–‡ä»¶ç»“æ„
        from app.core.git_manager import GitManager
        git_manager = GitManager()
        # é¦–å…ˆæ·»åŠ é¡¹ç›®åˆ°ç®¡ç†å™¨
        git_manager.add_project(request.project_path)
        project = git_manager.get_project(request.project_path)
        if not project:
            raise HTTPException(status_code=404, detail="Project not found")
        file_tree = project.get_file_tree(max_depth=2)
        
        # æ„å»ºåˆå§‹ç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç åˆ†æåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·åˆ†æé¡¹ç›®æ¶æ„ã€ä»£ç ç»“æ„å’ŒæŠ€æœ¯æ ˆã€‚

å½“å‰åˆ†æçš„é¡¹ç›®è·¯å¾„: {request.project_path}
é¡¹ç›®æ–‡ä»¶ç»“æ„:
{format_file_tree_for_ai(file_tree)}

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥è·å–æ›´å¤šä¿¡æ¯ï¼š
1. read_project_file - è¯»å–é¡¹ç›®æ–‡ä»¶å†…å®¹
2. list_project_files - åˆ—å‡ºé¡¹ç›®æ–‡ä»¶ç»“æ„
3. get_file_metadata - è·å–æ–‡ä»¶å…ƒæ•°æ®

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œæ™ºèƒ½åœ°ä½¿ç”¨è¿™äº›å·¥å…·æ¥è·å–æ‰€éœ€ä¿¡æ¯ï¼Œç„¶åè¿›è¡Œåˆ†æå’Œå›ç­”ã€‚
"""

        return {
            "conversation_id": conversation_id,
            "system_prompt": system_prompt,
            "project_path": request.project_path
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start conversation: {str(e)}")

@router.post("/smart-conversation/chat")
async def smart_chat(request: SmartConversationRequest) -> Dict[str, Any]:
    """æ™ºèƒ½å¯¹è¯èŠå¤©"""
    try:
        # ä½¿ç”¨é«˜çº§æ™ºèƒ½å¯¹è¯ç®¡ç†å™¨å¤„ç†è¯·æ±‚
        result = await advanced_smart_conversation_manager.process_smart_chat(
            request.conversation_id or f"conv_{int(time.time() * 1000)}",
            request.project_path,
            request.message or ""
        )
        
        return {
            "response": result["response"],
            "conversation_id": result["conversation_id"],
            "tool_calls": result["tool_calls"],
            "analysis_context": result.get("analysis_context", {})
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Smart chat failed: {str(e)}")

@router.post("/smart-conversation/end")
async def end_smart_conversation(request: SmartConversationRequest) -> Dict[str, Any]:
    """ç»“æŸæ™ºèƒ½å¯¹è¯ä¼šè¯"""
    return {
        "success": True,
        "message": "Conversation ended successfully",
        "conversation_id": request.conversation_id
    }
